# Day 02: Building a High-Performance Ingestion API with FastAPI & SQLite

**Date:** October 28, 2023
**Author:** dattskoushik
**Project:** [Day 02 - FastAPI Log API](../code_python/fastapi-log-api/)

---

## The Problem: Data Ingestion at Scale

In a distributed system, logs are generated by thousands of microservices simultaneously. Writing these logs directly to disk on each local machine creates a fragmented mess that is impossible to query holistically. We need a centralized ingestion funnel—a gateway that can accept high-velocity streams of log data, validate them for structural integrity, and persist them for downstream analysis.

The challenge is threefold:
1.  **Throughput:** The API must handle concurrent writes without blocking.
2.  **Validation:** Garbage data (malformed JSON, invalid enums) must be rejected at the gate.
3.  **Persistence:** Data must be stored reliably, even if it's just a lightweight buffer before a data lake.

Traditional frameworks like Flask or Django are often too heavy (blocking IO) or boilerplate-heavy for this specific microservice pattern.

## The Solution: Asynchronous FastAPI Architecture

For Day 02, I architected a lightweight REST API using **FastAPI**, **SQLAlchemy**, and **Pydantic**. This combination offers high performance (via Starlette) and rigorous data validation out of the box.

### 1. Schema-First Design with Pydantic V2

I defined strict data contracts using Pydantic models. This ensures that every incoming request is validated *before* it touches the business logic.

```python
class LogCreate(LogBase):
    severity: str = Field(..., min_length=2, max_length=20)

    @field_validator('severity')
    @classmethod
    def validate_severity(cls, v):
        allowed = {'INFO', 'WARN', 'ERROR', ...}
        if v.upper() not in allowed:
            raise ValueError(f"Severity must be one of {allowed}")
        return v.upper()
```

### 2. Dependency Injection for Database Sessions

To manage database connections efficiently, I utilized FastAPI's Dependency Injection system. This pattern ensures that a database session is created for each request and—crucially—closed afterwards, preventing connection leaks.

```python
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

### 3. Batch Ingestion Logic

Single-record inserts are a performance killer. I implemented a `/ingest` endpoint that accepts a list of records (`List[LogCreate]`). This reduces network overhead and allows for transactional writes—either the entire batch succeeds, or the transaction rolls back.

```python
@app.post("/ingest", response_model=List[LogRead], status_code=201)
def ingest_logs(logs: List[LogCreate], db: Session = Depends(get_db)):
    # ... mapping logic ...
    try:
        db.add_all(db_logs)
        db.commit()
    except Exception:
        db.rollback()
        raise HTTPException(status_code=500, detail="Database error")
```

## Use Cases

This architecture serves as the foundational "Collector" layer in a modern data platform:

*   **Centralized Logging:** Microservices forward their logs to this API instead of writing to local files.
*   **Audit Trails:** Financial or security systems can use this to create an immutable record of user actions.
*   **IoT Telemetry:** Edge devices can batch-upload sensor readings to this endpoint.

## Conclusion

By leveraging FastAPI's async capabilities and Pydantic's validation, we've built a robust ingestion engine in under 100 lines of code. It's type-safe, auto-documented (Swagger UI), and ready to scale.

Next up: **API Optimization**—adding pagination, filtering, and sorting to make our data retrievable.
